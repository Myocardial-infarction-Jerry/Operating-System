# 操作系统 Review

# Part.1 概论

## Chap.1 导论

### 1.1 操作系统的功能

系统基本计算资源: 硬件, 如 CPU、内存、I/O 设备

#### 1.1.1 用户视角

- 操作系统设计的主要目的是用户**使用方便**, 次要的是性能, 不在乎的是**资源利用**
- ![image-20230613102605928](/Users/qiu_nangong/Library/Application Support/typora-user-images/image-20230613102605928.png)

#### 1.1.2 系统视角

- 从计算机视角来看, 可将操作系统看作**资源分配器**
- 从用户程序需求来看, 可将操作系统看作**控制程序**

#### 1.1.3 操作系统的定义

- 摩尔定律: 集成电路可容纳元器件的数目每隔 18 个月便会翻倍
- 操作系统公认定义: 操作系统是一直运行在计算机上的程序 (通常称为**内核**)
  - 系统程序: 与系统运行有关的程序, 但不是内核的一部分
  - 应用程序: 与系统运行无关的所有其他程序

### 1.2 计算机系统的组成

### 1.2.1 计算机系统的运行

- **引导程序**: 一般位于计算机的固件, 如只读内存 (ROM) 或**电可擦可编程只读内存 (EEPROM)**
  - 初始化系统各个组件: CPU 寄存器, 设备控制器, 内存内容
  - 必须知道如何加载操作系统并且开始执行系统, 必须定位操作系统内核并且加到内存
- **系统进程**/系统后台程序: 启动并加到内存的系统程序, 生命周期与内核一样
  - 系统完全启动: 系统进程加载完成后
- **中断**: 事件发生标志
  - 硬件可以随时通过系统总线触发中断
  - 软件可以通过执行系统调用/监督程序调用触发中断
  - CPU 被中断时, 停止当前任务, 并立即转到固定位置继续执行
  - 指针表位于低地址内存, 包含各种设备的中断处理程序地址, 这些地址的数组称为**中断向量**

#### 1.2.2 储存结构

- 内存: 通常为**动态随机访问内存 (DRAM)**
  - 内存是易失性的储存设备, 掉电会失去所有内容
  - 内存容量小, 不能永久保存所有程序和数据
- 外存: 通常为**磁盘**或**硬盘**, 大多数程序都储存在硬盘时, 需要执行时才加载到内存, 是程序处理的起点与终点

#### 1.2.3 I/O 结构

- 操作系统为每个设备控制器提供一个**设备驱动程序**, 负责设备控制器, 并为操作系统的其他部分提供统一的设备访问接口
- 大量数据移动, 如磁盘 I/O, 可以采用**直接内存访问 (Direct Memory Access, DMA)**

### 1.3 计算机系统的体系结构

#### 1.3.1 单处理器系统

- 大多数系统仍采用单处理器
- 系统只有一个 “通用” CPU

#### 1.3.2 多处理器系统

- **多处理器系统**, 或称**并行系统/多核系统**, 具有多个 CPU, 这些 CPU 共享计算机总线、时钟、内存、外设等
- 多处理系统有主要三个优点:
  - 增加吞吐量: 通过增加处理器数量, 在更短时间内完成更多工作
  - 规模经济: 多处理器系统价格低于多个单处理器系统
  - 增加可靠性: 将功能分布在多个处理器上, 单个处理器的失灵不会使得整个系统停止
- 为增加计算机系统的可靠性
  - 根据剩余有效硬件的级别按比例继续提供服务, 称为**适度退化**
  - 容忍单个部件错误并继续运行, 称为**容错**
- 多处理器系统具有两种类型
  - **非对称处理**: 每个处理器有各自特定的任务, 由主处理器调度从处理器
  - **对称多处理**: 多个处理器参与完成操作系统的所有任务, 处理器之间没有主从关系, 相互独立
- 对处理器可是系统的内存访问模型, 从**均匀内存访问**改成**非均匀内存访问**

#### 1.3.3 集群系统

- **集群系统**: 将多个 CPU 组合在一起, 这样的系统称为**松耦合的**
- 就群通常用于提供**高可用性**服务
- **非对称集群**: 一台机器处于**热备份模式**, 另一台运行应用程序, 若活动服务器失效, 热备份主机称为活动服务器
- **对称集群**: 多个主机运行应用程序, 并相互监视
- **并行计算**: 将一个程序分成多个部分, 每个部分并行在计算机的各个核上

### 1.4 操作系统的结构

- **多道程序设计 (multiprogramming)** 通过安排作业时的 CPU 总有一个执行作业, 提高 CPU 利用率
- **作业池 (job pool)**: 包括磁盘上的, 等待分配内存的所有进程
- **分时系统 (或多任务 (multitasking))** 是多道程序设计的自然延伸
- 分时系统要求计算机系统是**可交互的**, 以便用户与系统直接通信, 响应时间应当较短, 通产小于 1s
- **进程 (process)**: 加载到内存并执行的程序
- **作业调度 (job scheduling)**: 若有多个作业可以加载到内存, 但内存太小而不能容纳所有作业, 系统做出选择
- **CPU 调度 (CPU scheduling)**: 若有多个任务同时等待执行, 系统做出选择
- **虚拟内存 (virtual memory)**: 用户可执行比**物理内存 (physical memory)** 大的程序, 将内存抽象成一个庞大的、同一个储存数组, 将用户理解的**逻辑内存 (logical memory)** 与物理内存区分开来

### 1.5 操作系统的执行

- 现在操作系统是**中断驱动 (interrupt driven)** 的
- **陷阱 (trap) (或异常 (exception))** 是一种软件生成的中断, 源于出错或用户程序的特定请求

#### 1.5.1 双重模式与多重模式的执行

- 操作系统至少需要两种单独运行模式: **用户模式 (user mode) 和 内核模式 (kernel mode)**, 计算机可以通过一个**模式位 (mode bit)** 来表示当前模式
- 双重模式执行提供保护手段: 将可能引起损害的机器指令作为**特权指令 (privileged instruction)**, 只允许在内核模式下执行
- 模式概念可以拓展以超过两个, 支持虚拟化 (virtualization) 的 CPU 有一种单独模式表示**虚拟机管理器 (Virtual Machine Manager, VMM)** 是否正在控制系统, 该模式特权多于用户模式, 但是少于内核模式

#### 1.5.2 定时器

- **定时器 (timer)**: 指定周期后中断计算机, 维持操作系统控制 CPU, 防止用户程序陷入死循环, 或不调用系统服务并且不将控制返还给操作系统
- **可变定时器 (variable timer)**: 指定周期可以固定或可变

### 1.6 进程管理

- 程序本身不是进程, 程序是个*被动实体 (passive entity)*, 如同存储在磁盘上的文件内容, 而进程是个*主动实体 (active entity)*
- **程序计数器 (program counter)**: 单线程进程用来指定下一个所执行的指令
- 操作系统负责进程管理的以下活动:
  - 在 CPU 上调度进程和线程
  - 创建和删除用户进程和系统进程
  - 挂起和重启进程
  - 提供进程同步机制
  - 提供进程通信机制

### 1.7 内存管理

- 内存是 CPU 能直接寻址和访问的、唯一的、大容量的存储器
- 若程序需要执行, 必须要映射到绝对地址, 并且加载到内存
- 操作系统负责内存管理的以下活动:
  - 记录内存的哪部分在被使用以及被谁使用
  - 决定哪些进程 (或其部分) 会调入或调出内存
  - 根据需要分配和释放内存空间

### 1.8 储存管理

- **文件 (file)**: 存储设备的逻辑存储单元

#### 1.8.1 文件系统管理

- 文件管理是操作系统最明显的组件之一
- 文件是创建者定义的相关信息组合
- 操作系统负责文件管理的以下活动:
  - 创建和删除文件
  - 创建和删除目录, 以便组织文件
  - 提供文件和目录的操作源语
  - 映射文件到外存
  - 备份文件到稳定的 (非易失的) 存储介质

#### 1.8.2 大容量存储器管理

- 操作系统负责有关硬盘管理的以下活动:
  - 空闲空间管理
  - 存储空间分配
  - 硬盘调度
- **三级存储 (tertiary storage)**: 磁带驱动器及磁带, CD/DVD 驱动器及光盘等, 分为**一次写多次读 (Write-Once Read-Many-Times, WORM)** 和**读——写 (Read-Write, RW)**

#### 1.8.3 高速缓存

- **高速缓存 (caching)**: 有时简称缓存, 用于临时保存信息以供更快调用

- **高速缓存管理 (cache management)**: 高速缓存大小有限, 慎重选择高速缓存大小与置换策略能大幅提高性能

- 各种级别存储的性能

  ![image-20230614151836540](/Users/qiu_nangong/Library/Application Support/typora-user-images/image-20230614151836540.png)

- **高速缓存一致性 (cache coherence)**: 对于多处理器环境, 数据的拷贝可能出现在多个缓存上以供并行执行, 应确保数据更新的一致性

#### 1.8.4 I/O 系统

- **I/O 子系统 (I/O subsystem)**: 为操作系统隐藏 I/O 设备的特性, 包含以下组件:
  - 包括缓冲、高速缓存和假脱机的内存管理组件
  - 设备驱动器的通用接口
  - 特定硬件设备的驱动程序

### 1.9 保护与安全

- **保护 (protection)**: 用于控制进程或用户访问计算机系统资源的一种机制, 提供制定和实施控制的手段
- **安全 (security)**: 防止系统不受内部或者外部的攻击, 如病毒和蠕虫、拒绝服务攻击、身份偷窃、服务偷窃
- **用户标识 (User ID, UID)**: 按照 Windows 的说法称为安全 ID (Secure ID, SID), 用以系统区分所有用户
  - **组标识 (group identifier)**: 区分用户集合
- **升级特权 (escalate privilege)**: 获得某个活动的额外许可

### 1.10 内核数据结构

#### 1.10.1 列表、堆栈及队列

#### 1.10.2 树

#### 1.10.3 哈希函数与哈希表

#### 1.10.4 位图

- **位图 (bitmap)**: 为 n 个二进制位的串, 用于表示 n 项的状态
- **磁盘块 (disk block)**: 磁盘的可用单元, 其可用性通过位图来表示

### 1.11 计算环境

#### 1.11.1 传统计算

#### 1.11.2 移动计算

#### 1.11.3 分布计算

- 分布式系统是物理上分开的、可能异构的、通过网络相联的一组计算机系统, 可供用户访问系统维护的各个资源
- **网络 (network)**: 多个系统之间的通信路径
- **传输控制协议/网间协议 (Transport Control Protocol/Internet Protocol, TCP/IP)**: 最常用的网络协议, 提供因特网的基础架构. 大多数操作系统都支持 TCP/IP, 包括所有通用协议
- 网络可以根据节点距离划分
  - **局域网 (Local-Area Network, LAN)**
  - **广域网 (Wide-Area Network, WAN)**
  - **城域网 (Metropolitan-Area Network, MAN)**
  - **个人局域网 (Personal-Area Network, PAN)**
- **网络操作系统 (network operating system)**: 提供跨网络文件分享、不同计算机进程的消息交换

#### 1.11.4 客户机——服务器计算

- 客户机——服务器系统的通用结构

  ![image-20230614154335813](/Users/qiu_nangong/Library/Application Support/typora-user-images/image-20230614154335813.png)

- 服务器系统可大致分为计算服务器和文件服务器

  - **计算服务器系统 (compute-server system)**: 提供接口, 以便客户发送请求执行操作, 并将结果发送到客户
  - **文件服务器系统 (file-server system)**: 提供文件系统接口, 以便客户可以创建、更新、访问、删除文件

#### 1.11.5 对等计算

- **对等 (Peer-to-peer, P2P)**: 分布式系统的另一结构
  - 所有系统节点都是对等的, 每个节点都可作为服务器或客户机, 取决于是请求还是提供服务
  - 判断哪些服务可用包括两种基本方法:
    - 当节点加入网络时, 通过网络集中查询服务来注册服务
    - 向网络所有其他节点, 广播服务请求, 已发现可提供服务节点

#### 1.11.6 虚拟化

- 虚拟化技术是一种软件技术, 用于实现模拟
- **模拟 (emulation)**: 当原有 CPU 类型与现有 CPU 类型不同, 可采用模拟
  - **解释 (interpretation)**: 将高级语言代码转换成原 CPU 的指令
- **虚拟化 (virtualization)**: CPU 架构相同时运行虚拟机的技术

#### 1.11.7 云计算

- **云计算 (cloud computing)**: 通过网络提供计算、存储、应用程序等服务
- 云计算有许多类型:
  - **公云 (public cloud)**
  - **私云 (private cloud)**
  - **混合云 (hybrid cloud)**
  - **软件即服务 (Software as a Service, SaaS)**
  - **平台即服务 (Platform as a Service, PaaS)**
  - **基础设施即服务 (Infrastructure as a Service, Iaas)**

#### 1.11.8 实时嵌入式系统

### 1.12 开源操作系统

## Chap.2 操作系统结构

### 2.1 操作系统的服务

- 提供用户功能:
  - **用户界面 (User Interface, UI)**:
    - **命令行界面 (Command-Line Interface, CLI)**
    - **批处理界面 (batch interface)**
    - **图形用户界面 (Graphical User Interface, GUI)**
  - **程序执行**: 系统加载程序到内存并运行
  - **I/O 操作**: 为程序提供 I/O 手段
  - **文件系统操作**
  - **通信:** 进程间交换信息
    - **共享内存 (shared memory)**: 多个进程读写共享内存区域
    - **消息交换 (message pasing)**: 符合预先定义格式的信息在进程间进行移动
  - **错误检测**
  - **资源分配**
  - **记账**: 记录用户使用资源的类型和数量, 用以分析提高效率
  - **保护与安全**

### 2.2 用户与操作系统的界面

#### 2.2.1 命令解释程序

- **外壳 (shell)**: 命令解释程序

#### 2.2.2 图形用户界面

- **桌面 (desktop)**: 基于鼠标的视窗和菜单系统

#### 2.2.3 界面的选择

### 2.3 系统调用

- **系统调用 (system call)**: 提供操作系统服务接口
- **应用编程接口 (Application Programming Interface, API)**:
  - 更好的可移植性
  - 易于使用
- **系统调用接口 (system-call interface)**
- 向操作系统传递参数:
  - 通过寄存器直接传递
  - 通过寄存器传入参数所在内存块或表的地址
  - 将参数压入到堆栈, 并由系统弹出

### 2.4 系统调用的类型

- 系统调用可大致分为六大类:
  - **进程控制 (process control)**
  - **文件管理 (file manipulation)**
  - **设备管理 (device manipulaiton)**
  - **信息维护 (information maintenance)**
  - **通信 (communication)**
  - **保护 (protection)**

#### 2.4.1 进程控制

- 执行程序应能正常 (end()) 或异常 (abort()) 停止执行.

  若系统调用异常停止当前执行程序, 或者程序执行遇到问题并引起错误陷阱, 将内存信息转储到磁盘, 用**调试器 (debugger)** 来分析**错误 (bug)**

- 部分命令

  ![image-20230619102451376](/Users/qiu_nangong/Library/Application Support/typora-user-images/image-20230619102451376.png)

- **锁定 (lock)**:

  用于协调并发进程, 如共享内存等

#### 2.4.2 文件管理

#### 2.4.3 设备管理

#### 2.4.4 信息维护

#### 2.4.5 通信

#### 2.4.6 保护

### 2.5 系统程序

- **系统程序 (system program)** 可分为以下几类:
  - **文件管理**
  - **状态信息**
  - **文件修改**
  - **程序语言支持**
  - **程序加载与执行**
  - **通信**
  - **后台服务**

### 2.6 操作系统的设计与实现

#### 2.6.1 设计目标

- **用户目标 (user goal) 和系统目标 (system goal)**

#### 2.6.2 机制与策略

- **机制 (mechanism)**: 决定如何做
- **策略 (policy)**: 决定做什么

#### 2.6.3 实现

### 2.7 操作系统的结构

#### 2.7.1 简单结构

#### 2.7.2 分层方法

#### 2.7.3 微内核

#### 2.7.4 模块

#### 2.7.5 混合系统

### 2.8 操作系统的调试

- **性能优化 (performance turning)**
- **瓶颈 (bottleneck)**

#### 2.8.1 故障分析

- **日志文件 (log file)**: 存储错误信息
- **核心转储 (core dump)**: 存储进程内存
- **崩溃 (crash)**: 内核故障
- **崩溃转储 (crash dump)**: 存储错误信息

#### 2.8.2 性能优化

- **跟踪列表 (trace listing)**: 记录系统运行相关事件、重要参数、时间

### 2.9 操作系统的生成

### 2.10 系统引导

- **系统引导 (booting)**: 加载内核以启动计算机
- **引导程序 (bootstrap program)** 或**引导加载程序 (bootstrap loader)**: 定位内核, 并加载到内存开始执行

# Part.2 进程管理

## Chap.3 进程

### 3.1 进程概念

- **进程 (process)**: 所有 CPU 活动

#### 3.1.1 进程

- **文本段 (text section)**: 程序代码

- **程序计数器 (program counter, PC)**

- **堆栈 (stack)**: 储存临时数据, 如函数参数、返回地址、局部变量

- **数据段 (data section)**: 全局变量等

- **堆 (heap)**: 进程运行时动态分配的内存

- 内存中的进程

  ![image-20230619104431930](/Users/qiu_nangong/Library/Application Support/typora-user-images/image-20230619104431930.png)

### 3.1.2 进程状态

- 每个进程可能处于以下状态:
  - **新的 (new)**: 进程正在创建
  - **运行 (running)**: 指令正在执行
  - **等待 (waiting)**: 进程等待发生某个事件
  - **就绪 (ready)**: 进程等待分配处理器
  - **终止 (terminated)**: 进程已经完成执行

#### 3.1.3 进程控制块

- **进程控制块 (Process Control Block, PCB)**, 也称为**任务控制块 (task control block)**: 储存进程相关信息:
  - **进程状态 (process state)**
  - **程序计数器 (program counter)**
  - **CPU 寄存器 (CPU register)**
  - **CPU 调度信息 (CPU-scheduling information)**
  - **内存管理信息 (memory-management information)**
  - **记账信息 (accounting information)**
  - **I/O 状态信息 (I/O status information)**

#### 3.1.4 线程

### 3.2 进程调度

- 多道程序设计: 无论何时都有进程运行, 最大化 CPU 利用率
- **进程调度器 (process scheduler)**: 选择可用进程到 CPU 上执行

#### 3.2.1 调度队列

- **作业队列 (job queue)**: 进程进入系统时加入, 包括系统内所有进程

- **就绪队列 (ready queue)**: 驻留在内存中的、就绪的、等待运行的进程. 通过链表 PCB 指向实现

- **设备队列 (device queue)**

- **队列图 (queueing diagram)**: 进程调度的通常表示

  ![image-20230619163053649](/Users/qiu_nangong/Library/Application Support/typora-user-images/image-20230619163053649.png)

- 进程运行过程如下:

  - 新进程被加到就绪队列
  - 进程在就绪队列中等待, 直到被选中执行或被**分派 (dispatched)**, 进程被分配到 CPU 执行时:
    - 进程可能发出 I/O 请求, 并被放到 I/O 队列
    - 进程可能创建一个新的子进程, 并等待其终止
    - 进程可能由于中断而被强制释放 CPU, 并被放回到就绪队列

#### 3.2.2 调度程序

- **调度器 / 调度程序 (scheduler)**: 进程调度选择程序
- **长期调度程序 (long-term scheduler) / 作业调度程序 (job scheduler)**: 从进程缓冲池中选择进程, 并加载到内存准备执行
  - 执行并不频繁
  - 控制**多道程序调度 (degree of multiprogramming)**
  - 仅有程序离开系统时才需要运行
  - 可进行认真选择, 通常进程可分为:
    - **I/O 密集型进程 (I/O-bound process)**
    - **CPU 密集型进程 (CPU-bound process)**

- **短期调度程序 (short-term scheduler) / CPU 调度程序 (CPU scheduler)**: 从准备执行的进程中选择进程, 并分配给 CPU
  - 必须经常为 CPU 选择新的进程
  - 速度必须快速, 否则将会有大量 CPU 时间浪费在调度工作上

#### 3.2.3 上下文切换

- 中断导致 CPU 从执行当前任务改变到执行内核程序, 在其发生时, 系统需要保存当前运行在 CPU 上的进程的上下文, 以便在处理后能够恢复**上下文**

- **上下文**: 通常采用进程 PCB 表示, 包括

  - CPU 寄存器的值
  - 进程状态
  - 内存管理信息

- **状态保存 (state save) / 状态恢复 (state restore)**
  - **上下文切换 (context switch)**: 切换 CPU 到另一个进程需要保存当前进策划功能状态和恢复另一个进程的状态

### 3.3 进程运行

#### 3.3.1 进程创建

- **进程树 (process tree)**: 进程在执行过程中可能创建多个新的进程, 形成父子进程, 进而形成进程树
- **进程标识符 (process identifier, pid)**: 进程的识别号
- 子进程可以从操作系统直接获得资源, 也可以只从父进程那里获得资源子集, 限制子进程只能使用父进程的资源, 可以防止创建过多进程, 导致系统超载.
- 当进程创建新进程时, 有两种执行可能:

  - 父进程与子进程并发执行
  - 父进程等待, 直到某个或者全部子进程执行完毕

  新进程的地址空间也有两种可能:

  - 子进程是父进程的复制品 (与父进程具有相同的程序和数据)
  - 子进程加载另一个新程序

#### 3.3.2 进程终止

- 终止时返回状态值到父进程, 所有进程资源由操作系统释放
- 父进程终止子进程的原因:
  - 子进程使用了超过他所分配的资源
  - 分配给子进程的任务不再需要
  - 父进程正在退出, 而且操作系统不允许无父进程的子进程继续执行
- **级联终止 (cascade termination)**: 若一个进程终止, 其所有子进程也应终止
- **僵尸进程 (zombie process)**: 当进程终止时并释放资源后, 进程表中条目仍然存在, 直到父进程调用 `wait()` 来获取进程表中其状态. 所有进程终止时都会过度到此状态, 一般只会短暂存在
- **孤儿进程 (orphan process)**: 若父进程没有调用 `wait()` 便终止, 导致子进程成为孤儿进程. Linux 和 UNIX 的处理方式是, 将 init 进程作为孤儿进程的父进程, 定期调用 `wait()` 以便收集退出状态并释放孤儿进程标识符和进程表条目

### 3.4 进程间通信

- 若一个进程不能影响其他进程或者受其他进程影响, 那么该进程是独立的

- 提供环境允许进程协作, 有以下理由:

  - **信息共享 (information sharing)**
  - **计算加速 (computation speedup)**
  - **模块化 (modularity)**
  - **方便 (convenience)**

- **进程间通信 (InterProcess Communication, IPC)**: 协作进程机制, 允许进程相互交换数据与信息, 有两种基本模型:
  - **共享内存 (shared memory)**

  - **消息传递 (message passing)**

#### 3.4.1 共享内存系统

- **生产者 (producer)** 进程生成信息, 以供**消费者 (comsumer)** 进程消费
- 解决生产者 - 消费者问题的方法之一是, 采用共享内存. 为了允许两者并发执行, 应有一个可用的缓冲区, 驻留在两者的共享内存区域之间
- 缓冲区可分为两种:
  - **无界缓冲区 (unbounded-buffer)**: 没有限制缓冲区的大小, 消费者可能等待, 但生产者总能生产
  - **有界缓冲区 (bounded-buffer)**: 缓冲区大小固定, 若缓冲区空, 则消费者等待, 若缓冲区满, 则生产者等待

#### 3.4.2 消息传递系统

- 消息传递提供一种机制, 以便允许进程不必通过共享地址空间来实现通信和同步
- 若进程间需要通信, 则必须之间具有**通信链路 (communication link)**, 其中用于逻辑实现链路和操作 `send()/receive()` 的方法有:
  - 直接或间接的通信
  - 同步或异步的通信
  - 自动或显式的缓冲

##### 3.4.2.1 命名

- **直接通信 (direct communication)**

  - 原语定义如下:

    - `send(P, message)`: 向 P 发送 message
    - `receive(Q, message)`: 从 Q 接受 message

  - 这种方案的通信链路有以下属性:

    - 在需要通信的进程之间, 自动建立链路, 仅需知道对方身份就可进行交流
    - 每个链路只与两个进程有关
    - 每对进程之间只有一个链路

##### 3.4.2.2 同步

- 消息传递可以是**阻塞 (blocking)** 或**非阻塞 (nonblocking)**, 或者称为**同步 (synchronous)** 或**异步 (asynchronous)**

  - **阻塞发送 (blocking send)**: 发送进程阻塞, 直到消息被接受
  - **非阻塞发送 (nonblocking send)**: 发送进程发送后恢复操作
  - **阻塞接受 (blocking receive)**: 接受进程阻塞, 直到有消息可用
  - **非阻塞接受 (nonblocking receive)**: 接受进程接收到一个有效消息或空消息

  **交会 (rendezvous)**: 当 `send()/receive()` 都是阻塞的

##### 3.4.2.3 缓存

- 进程交换的消息总是驻留在临时队列中, 队列实现有以下方法:

  - **零容量 (zero capacity)**: 队列的最大长度为 0, 因此链路中不能有任何消息处于等待, 即阻塞发送
  - **有限容量 (bounded capacity)**: 队列长度为有限的 n, 即链路已满时发送者应阻塞, 知道有可用空间为止
  - **无限容量 (unbouned capacity)**: 队列长度无限你, 发送者从不阻塞

  零容量情况称为无缓冲的消息系统, 其他情况称为自动缓冲的消息系统

### 3.6 客户机/服务器通信

#### 3.6.1 套接字

- **套接字 (socket)**: 通信的端点, 由一个 IP 地址和一个端口号组成. 通常服务器监听指定端口, 来等待客户请求
- 客户进程发出请求时, 主机分配一个 端口号>1024 的端口, 与服务器的某个端口建立连接. 所有链接必须是唯一的.

#### 3.6.2 远程过程调用

- **远程过程调用 (Remote Procedure Call, RPC)**: 抽象封装了网络系统之间的过程调用
- **存根 (stub)**: 客户端对目的过程的指向连接
- **封装 (marshal)**: 封装参数打包参数, 通过网络传输到进程

## Chap.4 多线程编程

### 4.1 概述

- 每个线程是 CPU 使用的基本单元, 下图说明了**单线程进程 (single-threaded)** 和**多线程进程 (multithreaded)** 之间的区别

  ![image-20230624164927944](/Users/qiu_nangong/Library/Application Support/typora-user-images/image-20230624164927944.png)

#### 4.1.1 动机

- 部分情况下, 单个应用可能需要执行多个同类任务, 若作为单个线程的传统进程来执行, 那么一次只能处理一个请求, 客户可能需要等待很长时间以便请求得到处理

#### 4.1.2 优点

- 多线程编程具有以下优点:
  - **响应性**: 若一个多线程部分阻塞或执行冗长操作, 仍能继续执行, 从而增加对用户的响应程度
  - **资源共享**: 允许一个应用程序在同一地址空间内有多个不同活动线程
  - **经济**: 进程创建所需的内存和资源分配十分昂贵, 而线程创建和切换更加经济
  - **可伸缩性**: 对于多处理器结构, 线程可在多处理核上并行运行

### 4.2 多核编程

- **多核 (multicore) / 多处理器 (multiprocessor)**: 多个计算核在多个或单个 CPU 芯片上

- **并行性 (parallelism) / 并发性 (concurrency)**: 没有并行, 并发也是可能的

- **Amdahl 定律**:
  $$
  加速比\leq\frac1{S+\frac{1-S}N}
  $$

#### 4.2.1 编程挑战

- 多核系统编程有以下挑战:
  - **识别任务**: 涉及分析应用程序, 查找区域以便氛围独立的、并发的任务
  - **平衡**: 在识别可以并行运行任务时, 程序员应确保任务执行同等价值的工作
  - **数据分割**: 正如应用程序要分为单独任务, 由任务访问和操作的数据也应划分以便运行在单独的核上
  - **数据依赖**: 任务访问的数据必须分析多个任务之间的依赖关系. 当存在依赖关系时, 必须确保任务执行是同步的
  - **测试与调试**: 当程序并行运行于多核时, 许多不同的执行路径是可能的

#### 4.2.2 并行类型

- **数据并行 (data parallelism)**: 注重将数据分布于多个计算核上, 并在每个核上执行相同操作
- **任务并行 (task parallelism)**: 设计将任务而不是数据分配到多个计算核, 每个核上执行独立的操作, 可以操控相同或不同的数据

### 4.3 多线程模型

- **用户线程 (user thread)**
- **内核线程 (kernel thread)**

#### 4.3.1 多对一模型

- 映射多个用户级线程到一个内核线程. 
- 线程管理由用户空间的线程库来完成, 效率高. 
- 如果一个线程执行阻塞系统调用, 则整个进程阻塞
- 无法利用多个处理核, 几乎被弃用

#### 4.3.2 一对一模型

- 映射每个用户线程到一个内核线程. 
- 当一个线程执行阻塞系统调用时, 允许另一个线程继续执行, 提供了更好的并发功能
- 创建内核线程的开销大, 限制了系统支持的线程数量

#### 4.3.3 多对多模型

- 多路复用多个用户及线程到同样数量或更少数量的内核线程
- 可以创建任意多的用户线程, 并且相应内核线程能再多处理器系统上并发执行
- **双层模型 (tow-level model)**“ 允许绑定某个用户线程到一个内核线程

### 4.4 线程库

- **线程库 (thread library)**: 为程序员提供创建和管理线程的 API
- 主要实现方法有:
  - 在用户空间中提供一个没有内核支持的库. 代码和数据结构都属于用户空间
  - 实现由操作系统直接支持的一个内核级的库. 代码和数据结构位于内核空间, 调用 API 函数通常会导致对内核的系统调用

#### 4.4.1 Pthreads

- **Pthreads** 是 POSIX 标准定义的线程创建与同步 API, 这仅为线程行为的规范, 而不是实现
- Pthreads 程序包括头文件 *pthread.h*:
  - `pthread_t tid` 声明了创建进程的标识符
  - `pthread_attr_t attr` 表示线程属性, 通过调用 `pthread_attr_init(&attr)` 可以设置这些属性
  - `pthread_create()` 可以创建一个单独线程
  - `pthread_join()` 父进程调用子进程并等待完成
  - `pthread_exit()` 子进程终止函数

#### 4.4.2 Windows 线程

- 使用 Windows API 应包含 *windows.h*
  - `CreateThread()` 线程创建函数
  - `WaitForSingleObject()` 形同 `pthread_join()`
  - `WaitForMultipleObjects()` 等待多个线程完成, 需要 4 个参数
    - 等待对象的数量
    - 对象数组的指针
    - 是否等待所有对象信号的标志
    - 超时时长 (或 INFINITE (无穷))

#### 4.4.3 Java 线程

- Java 程序的线程是程序执行的基本模型, 所有提供 JVM 的系统都可以运行 Java 线程

- Java 一般有两种方式创建线程:

  - 创建一个新的 Thread 派生类, 重载 `run()` 函数

  - 定义一个实现接口 `Runnable` 的类, 定义如下:

    ```java
    public interface Runnable {
    	public abstract void run();
    }
    ```

    当一个类实现接口 `Runnable` 时, 必须定义一个方法 `run()`, 其实现代码就是作为一个单独线程来运行的

- 创建 Thread 对象不会创建新的进程, 实际上在调用 `start()` 时才会创建新的线程, 该方法做两件事:

  - JVM 中, 为新线程分配资源并初始化
  - 调用方法 `run()`, 以便能在 JVM 中运行

### 4.5 隐式多线程

- **隐式线程 (implicit threading)**: 将多线程的创建与管理交给编译器和运行时库来完成

#### 4.5.1 线程池

- 当服务器收到请求时, 通过创建单独线程来处理请求. 但创建线程时间开销不可估计, 以及工作完成后线程会被丢弃, 高并发时会耗尽系统资源
- 在进程开始时创建一定数量线程, 并加入池中等待工作, 有空闲线程工作, 无空闲线程等待
- 线程池有以下优点:
  - 用现有线程服务请求比等待创建一个线程更快
  - 线程池限制了任何时候可用线程的数量, 对于不支持高并发的系统友好
  - 将要执行任务从创建任务的机制中分离出来, 允许采用不同策略运行任务

#### 4.5.2 OpenMP

- OpenMP 为一组编译指令和 API, 支持共享内存环境下的并行编程
- OpenMP 识别**并行区域 (parallel region)**, 即可并行运行的代码块
- `#pragma omp parallel`: OpenMP 会创建与系统处理核一样多的线程, 同时执行并行区域, 当每个线程退出并行区域时, 也就终止了
- `#pragma omp parallel for`: 提供了循环并行化, 用于运行并行区域的代码

#### 4.5.3 大中央调度

- **大中央调度 (Grand Central Dispatch, GCD)**: Apple Mac OS X 和 iOS 操作系统的一种技术, 允许应用程序将某些代码区段并行运行. 其管理大多数的多线程细节.
- GCD 为 C/C++ 语言增加了**块 (block)** 的拓展, 通过将这些块放置在**调度队列 (dispatchqueue)** 上, GCD 调度块以便执行.
- 每个进程都有自己的串行队列, 称为它的**主队列 (main queue)**

### 4.6 多线程问题

#### 4.6.1 系统调用 fork() 和 exec()

- 若程序内某个线程调用 `fork()`, 有两种形式:
  - 新进程复制所有线程
  - 新进程仅仅复制调用了系统调用 `fork()` 的线程
- 若程序内某个线程调用 `exec()`, 参数指定的程序将会取代整个进程, 包括所有线程
- 上述两种形式的 `fork()` 使用取决于应用程序, 若 `fork()` 后立即调用 `exec()`, 则没有必要复制所有线程

#### 4.6.2 信号处理

- **UNIX 信号 (signal)**: 用于通知进程某个特定事件已经发生, 其接受可以同步或者异步. 所有信号遵循相同模式:
  - 信号是由特定事件的发生而产生的
  - 信号被传递给某个进程
  - 信号一旦收到就应处理
- 信号处理程序可以分为:
  - 缺省的信号处理程序
  - 用户定一个信号处理程序
- 每个信号都有一个**缺省信号处理程序 (default signal handler)**, 有内核运行, 可以通过**用户定义信号处理程序 (user_defined signal handler)** 来改写
- 信号传递通常有以下选择:
  - 传递信号到信号所使用的线程
  - 传递信号到进程内的每个线程
  - 传递信号到进程内的某些线程
  - 规定一个特定线程以接受进程的所有信号
- 传递信号的标准 UNIX 函数为 `kill(pid_t pid, int signal)`, 该函数允许将特定信号传递到一个进程
- 由于信号只能处理一次, 所以信号通常传到第一个不拒绝他的线程, POSIX Pthreads 提供了函数 `pthread_kill(pthread_t tid, int signal)`

#### 4.6.3 线程撤销

- **线程撤销 (thread cancellation)** 是在线程完成之前终止线程
- 需要撤销的线程, 通常称为**目标线程 (target thread)**, 有两种情况:
  - **异步撤销**: 一个线程立即终止目标线程
  - **延迟撤销**: 目标线程不断检查其是否应该终止, 允许目标线程有机会有序终止自己
- 缺省撤销类型为延迟撤销, 这样仅有**线程到达撤销点 (cancellation point)**时, 才会发生撤销
- **清理处理程序 (cleanup handler)**: 释放撤销线程可能获得的任何资源

#### 4.6.4 线程本地存储

- **线程本地存储 (Thread-Local Storage, TLS)**: 每个线程需要自己的某些数据, 而不是同一进程的线程共享进程的数据

#### 4.6.5 调度程序激活

- **轻量级进程 (LightWeight Process, LWP)**: 在实现多对多或双层模型时, 在用户和内核线程之间增加一个中间数据结构, 其表现为虚拟处理器, 以便应用程序调度并运行用户线程
- **调度器激活 (scheduler activation)**: 内核提供一组虚拟处理器给应用程序, 而应用程序可以调度用户线程到任何一个可用虚拟处理器
- **回调处理程序 (upcall handler)**: 内核将有关特定时间通知应用程序

### 4.7 操作系统例子

#### 4.7.1 Windows 线程

- Windows 采用一对一映射, 线程一般包括如下部件:

  - 线程 ID, 用于唯一标识线程
  - 寄存器组, 用于表示处理器状态
  - 用户堆栈, 以供线程在用户模式下运行; 内核堆栈, 以供线程在内核模式下运行
  - 私有存储区域, 用于各种运行时库和动态链接库 (DLL)

  上述通常称为**线程上下文 (context)**

- 线程的主要数据结构包括:

  - ETHREAD: 执行线程块
  - KTHREAD: 内核线程块
  - TEB: 线程环境块

#### 4.7.2 Linux 线程

- `fork()` 提供进程复制的传统功能

- `clone()` 提供创建线程的功能, 调用 `clone()` 时, 需要传递一组标志, 以便确定父任务和子任务如何共享

  ![image-20230625030304646](/Users/qiu_nangong/Library/Application Support/typora-user-images/image-20230625030304646.png)

- Linux 并不区分进程和线程

## Chap.5 进程调度

### 5.1 基本概念

- **CPU 调度**: 最大化 CPU 利用率, 由操作系统介入在进程间转接 CPU 控制权

#### 5.1.1 CPU-I/O 执行周期

- 进程执行包括**周期 (cycle)** 进行 CPU 执行和 I/O 等待, 进程从 **CPU 执行 (CPU burst)**, 之后 **I/O 执行 (I/O burst)**

- 进程之间运行情况有下图

  ![image-20230625030955721](/Users/qiu_nangong/Library/Application Support/typora-user-images/image-20230625030955721.png)

  选择合适的 CPU 调度算法, 其分布非常重要

#### 5.1.2 CPU 调度程序

- **短期调度程序 (short_term scheduler)**: CPU 空闲时, 操作系统从就绪队列中选择一个进程来执行

#### 5.1.3 抢占调度

- 需要 CPU 调度的情况有:
  - 当一个进程从运行状态切换到等待状态时
  - 当一个进程从运行状态切换到就绪状态时
  - 当一个进程从等待状态切换到就绪状态时
  - 当一个进程终止时
- **非抢占的 (nonpreemptive) / 协作的 (cooperative)**: 调度只能发生在上述 1/4 情况时
- **抢占的 (preemptive)**: 非抢占的其余情况

#### 5.1.4 调度程序

- **调度程序 (dispatcher)**: 用于将 CPU 控制交给由短期调度程序选择的进程:

  - 切换上下文

  - 切换到用户模式

  - 跳转到用户程序的合适位置, 以便重新启动程序

- 调度程序停止一个进程而启动另一个所需的时间称为**调度延迟 (dispatch latency)**

### 5.2 调度准则

- 为了比较 CPU 调度算法, 有以下准则:
  - **CPU 使用率**: CPU 应该尽可能忙碌
  - **吞吐量 (throughput)**: 若 CPU 忙于执行进程, 则工作正在完成, 定义为单位时间内完成进程的数量
  - **周转时间 (turnaround time)**: 运行进程需要的时间, 从进程提交到进程完成的时间
  - **等待时间**: CPU 调度算法并不影响进程运行的时间, 等待时间为就绪队列中等待所花时间之和
  - **响应时间**: 从提交请求到产生第一响应的时间
- 最大化 CPU 使用率和吞吐量, 最小化周转时间、等待时间、响应时间

### 5.3 调度算法

#### 5.3.1 先到先服务调度

- **先到先服务 (First-Come First_Served, FCFS)**

#### 5.3.2 最短作业优先调度

- **最短作业优先 (Shotest-Job-First, SJF)**: 赋给具有最短 CPU 执行的进程
- 困难在于如何估计下次 CPU 执行的长度

#### 5.3.3 优先级调度

- **优先级调度 (priority_scheduling)**: 最高优先级的进程会分配到 CPU
- 主要问题是**无穷阻塞 (indefinite blocking)** 和**饥饿 (starvation)**, 可能会导致某个低优先级进程无穷等待 CPU, 解决方案之一为**老化 (aging)**, 即在等待时间增长时提升其优先级

#### 5.3.4 轮转调度

- **轮转 (Round-Robin, RR)**: 为分时系统设计, 类似于 FCFS 调度, 但是增加了抢占以切换进程
- **时间量 (time quantum) / 时间片 (time slice)**: 为每个进程分配不超过一个时间片的 CPU

#### 5.3.5 多级队列调度

- **前台进程 (foreground process) / 后台进程 (background process)**
- **多级队列 (multilevel queue)**: 将就绪队列分成多个单独队列, 根据进程属性调度

#### 5.3.6 多级反馈队列调度

- **多级反馈队列 (multilevel feedback queue)**: 允许进程在队列之间迁移

### 5.4 线程调度

- 在支持线程的操作系统上, 内核级线程才是操作系统所调度的, 用户级线程由线程库来管理, 内核并不知道其存在

#### 5.4.1 竞争范围

- **进程竞争范围 (Process-Contention Scope, PCS)**: 对于实现多对一和多对多模型的系统线程库会调度用户级线程, 以便在可用 LWP 上运行
- **系统竞争范围 (System-Contention Scope, SCS)**: 决定那个内核级线程调度到处理器上

#### 5.4.2 Pthreads 调度

- 在线程创建时允许指定 PCS 或 SCS 的 POSIX Pthreads API:
  - `PTHREAD_SCOPE_PROCESS`: 按 PCS 来调度线程, 通过调度用户级线程到 LWP, 实际为多对多模型
  - `PTHREAD_SCOPE_SYSTEM`: 按 SCS 来调度线程, 通过创建 LWP 并将其绑定到每个用户级线程, 实际采用一对一策略来映射线程

### 5.5 多处理器调度

- **负载分配 (load sharing)**: 多个 CPU 调度问题, 更复杂

### 5.6 实时 CPU 调度

- **软实时系统 (soft real-time system)**: 不保证会调度关键是是进程, 只保证这类进程优先于非关键进程
- **硬实时系统 (hard real-time system)**: 严格要求任务在期限前完成, 期限后完成与没有完成完全一样

#### 5.6.1 最小化延迟

- **事件延迟 (event latency)**: 从事件发生到事件得到服务的这段时间
- 两种类型的延迟影响实时系统的性能:
  - **中断延迟 (interrupt latency)**: 是从 CPU 收到中断到中断处理程序开始的时间
  - **调度延迟 (dispatch latency)**: 调度程序从停止一个进程到启动另一个进程所需的时间, 保持该延迟尽可能低的最有效技术是, 提供抢占式内核

#### 5.6.2 优先权调度

- 实时操作系统最重要功能是: 当实时进程需要 CPU 时立即响应

## Chap.6 同步

- **协作进程 (cooperating process)**: 能与系统内其他执行进程相互影响

### 6.1 背景

- **竞争条件 (race condition)**: 多个进程并发访问同一数据并且执行结果与特定访问顺序有关
- **进程同步 (process synchronization) / 进程协调 (process coordination)**

### 6.2 临界区问题

- **临界区 (critical section)**: 进程在执行该区时可能修改公共变量、更新一个表、写一个文件等

- **进入区 (entry section)**: 实现进入临界区的请求许可代码

- **退出区 (exit section)**

- **剩余区 (remainder section)**: 其他代码

  ![image-20230625155954657](/Users/qiu_nangong/Library/Application Support/typora-user-images/image-20230625155954657.png)

- 临界区问题解决方案应满足以下要求:

  - **互斥 (mutual exclusion)**: 若有进程在临界区内执行, 那么其他所有进程都不能在其临界区执行
  - **进步 (progress)**: 若没有进程在其临界区内执行, 并且有进程需要进入临界区, 那么只有不再剩余区内执行的进程可以参加选择, 此种选择不能无限推迟
  - **有限等待 (bounded waiting)**: 从一个进程作出进入临界区的请求知道这个请求允许为止, 其他进程允许进入其临界区的次数具有上限

- 处理临界区问题有两种方法:

  - **抢占式内核 (preemptive kernel)**: 允许处于内核模式的进程被抢占
  - **非抢占式内核 (nonpreemptive kernel)**: 不允许处于内核模式的进程被抢占, 该进程会一直运行知道退出内核模式、阻塞或自愿放弃 CPU 控制

### 6.3 Peterson 解决方案

- 进程共享两个数据项:

  ```pseudocode
  int turn;
  boolean flag[2];
  ```

  turn 表示那个进程能够进入临界区, flag表示那个进程准备进入临界区

  ![image-20230625162251693](/Users/qiu_nangong/Library/Application Support/typora-user-images/image-20230625162251693.png)

### 6.4 硬件同步

- **加锁 (locking)**: 通过锁来保护临界区
- **原子的 (atomically)**: 不可中断的指令

### 6.5 互斥锁

- **互斥锁 (mutex lock)**: 在进入临界区时获取锁, 在退出临界区时释放锁

  ![image-20230625163210623](/Users/qiu_nangong/Library/Application Support/typora-user-images/image-20230625163210623.png)

  其实现需要**忙等待 (busy waiting)**, 即获取锁实现如下

  ```c++
  void acquire() {
  		while (!available); // busy wait
  		available = false;
  }
  
  void release() {
    available = true;
  }
  ```

### 6.6 信号量

- **信号量 (semaphore)**: 是一个整形变量, 仅能通过两个标准原子操作来访问:
  - `wait()`
  - `signal()`

#### 6.6.1 信号量的使用

- **计数信号量 (counting semaphore)**: 值不受限制
- **二进制信号量 (binary semaphore)**: 值只能为 0/1, 类似于互斥锁

#### 6.6.2 信号量的实现

- `wait()` 内发现信号量值不为正时, `block()` 阻塞进程并放入等待队列, 减少了忙等待的时间
- `signal()` 释放信号量, 并通过 `wakeup()` 重新执行先前阻塞的进程

#### 6.6.3 死锁与饥饿

- **死锁 (deadlocked)**: 两个或多个进程无限等待一个事件, 而该事件仅能由这些等待进程之一来产生
- **无限阻塞 (indefinite blocking) / 饥饿 (starvation)**: 进程无限等待信号量

#### 6.6.4 优先级的反转

- **优先级反转 (priority inversion)**: 较高优先级的进程需要访问被较低优先级进程占用的内核数据
- **优先级继承协议 (priority-inheritanec protocol)**: 正在访问资源的进程获得需要访问他的更高优先级进程的优先级, 直到用完相关资源为止恢复到原先优先级

### 6.7 经典同步问题

#### 6.7.1 有界缓冲问题

- 生产者 - 消费者问题

  ![image-20230625170232352](/Users/qiu_nangong/Library/Application Support/typora-user-images/image-20230625170232352.png)

#### 6.7.2 读者 - 作者问题

#### 6.7.3 哲学家就餐问题

### 6.8 管程

- **管程 (monitor)**: 一种高级同步工具, 处理同步机制仍不能处理的死锁问题

#### 6.8.1 使用方法

- **抽象数据类型 (Abstract Data Type, ADT)**: 封装数据及操作函数, 管程属于 ADT 类型
- 管程结构确保每次只有一个进程在管程内处于活动状态, 不需要明确编写同步约束
- 管程变量被进程 P 调用时, 并且正有一个挂起进程 Q, 若 Q 允许重执行, 有两种可能性:
  - **唤醒并等待 (signal and wait)**: 进程 P 等待直到 Q 离开管程, 或者等待另一个条件
  - **唤醒并继续 (signal and continue)**: 进程 Q 等待直到 P 离开管程, 或者等待另一个条件

### 6.9 同步例子

#### 6.9.1 Windows 同步

- 当内核访问全局资源时, 屏蔽中断

- 对于多处理器系统, 使用自旋锁来保护访问全局资源, 内核不会抢占拥有自旋锁的线程

- 用户空间提供**调度对象 (dispatcher object)**, 包括互斥锁、信号量、事件和定时器等

- **事件 (event)**: 类似于条件

- **触发状态 (signaled state)**: 对象可用, 线程获取时不会阻塞

- **非触发状态 (nonsignaled state)**: 对象不可用, 线程获取时会阻塞

  ![image-20230625214122568](/Users/qiu_nangong/Library/Application Support/typora-user-images/image-20230625214122568.png)

- **临界区对象 (critical-section object)**: 为用户模式互斥锁, 可在没有内核干预的情况下获取和释放. 本质上是自旋锁, 自旋时间过长时会分配一个互斥锁, 并放弃 CPU, 是高效的

#### 6.9.2 Linux 同步

- v2.6 前是非抢占式的
- 提供信号量、原子整数、自旋锁以及这些的读者 - 作者版本
- 单 CPU 下 Linux 采用启用/禁用内核抢占来实现自旋锁

#### 6.9.3 Solaris 同步

- 提供自适应互斥锁、条件变量、信号量、读写锁、十字转门

- **自适应互斥 (adaptive mutex)**: 保护访问每个临界数据项
  - 作为标准信号量, 采用自旋锁来实现
  - 若数据被上锁, 有两个选择:
    - 若当前锁被 CPU 上运行的线程拥有, 该线程可能很快结束, 请求该锁的所有线程自旋
    - 若拥有当前锁的线程不处于运行状态, 请求该锁的线程阻塞并睡眠, 直到该锁释放时被唤醒
- **十字转门 (turnstile)**: 包含阻塞在锁上、排列等待获取自适应锁和读写锁的线程
  - 若一个线程拥有锁, 其他线程在获取锁时会阻塞并进入该锁的十字转门
  - **优先级继承协议 (priority-inheritance protocol)**: 十字转门根据此防止优先级反转

#### 6.9.4 Pthreads 同步

- Pthreads API 仅能被用户级别的程序员使用
- 提供互斥锁、条件变量和读写锁

### 6.10 替代方法

#### 6.10.1 事务内存 (transactional memory)

- **内存事务 (memory transaction)**: 为一个内存读写操作的序列, 原子的. 
  - 若事务中的所有操作都完成了, 内存事务被提交.
  - 否则, 终止操作并回滚

#### 6.10.2 OpenMP

#### 6.10.3 函数式编程语言

- **不可变 (immutable)**: 在被赋值后, 值不可变, 语言不维护状态

## Chap.7 死锁

- **死锁 (deadlock)**: 进程申请的资源被其他等待进程占有, 永远无法改变等待状态

### 7.1 系统模型

- 系统拥有若干资源, 如 CPU 周期、内存空间、I/O 设备, 这些资源又有若干实例
- 正常操作模式下, 进程使用资源顺序如下:
  - **申请**: 进程请求资源, 若申请不能被立即允许, 则进程等待
  - **使用**: 进程对资源进行操作
  - **释放**: 进程释放资源

### 7.2 死锁特征

#### 7.2.1 必要条件

- 若一个系统中下列条件同时成立, 那么就能引起死锁:
  - **互斥 (mutual exclusion)**: 至少有一个资源处于非共享模式, 一次只有一个进程可使用
  - **占有并等待 (hold and wait)**: 一个进程应占有至少一个资源, 并等待另一个被其他进程占有的资源
  - **非抢占 (no preemption)**: 资源不能被抢占, 即资源只能在进程完成任务后自愿释放
  - **循环等待 (circular wait)**: 有一组等待进程 {P_0, P_1, ..., P_n}, P_i 等待的资源被 P_i+1 占有

#### 7.2.2 资源分配图

- **系统资源分配图 (system resource-allocation graph)**

  ![image-20230625224009035](/Users/qiu_nangong/Library/Application Support/typora-user-images/image-20230625224009035.png)

- **申请边 (request edge)**: P->R

  **分配边 (assignment edge)**: R->P

- 圆形表示进程, 矩形表示资源

- 若图上没有环, 则不存在死锁, 否则可能存在死锁

### 7.3 死锁处理方法

- 一般处理死锁问题有三种办法:

  - 通过协议来预防或避免死锁, 确保系统不会进入死锁状态

  - 可以允许系统进入死锁状态, 然后检测他, 并加以恢复

  - 忽视该问题, 认为死锁不可能发生

- **死锁预防 (deadlock prevention)**: 破坏上面四个必要条件之一

- **死锁避免 (deadload avoidence)**: 操作系统事先得到有关进程申请资源和使用资源的额外信息, 考虑是否立即或延迟分配资源

### 7.4 死锁预防

- 破坏以下四个条件之一, 就能预防死锁发生

#### 7.4.1 互斥

- 破坏 “至少有一个资源非共享” 这一条件

#### 7.4.2 持有并等待

- 保证进程申请资源时, 其不能占有其他资源

  - 每个进程在执行前申请获得所有资源
  - 仅允许进程在没有资源时申请资源

  上述协议有两个缺点:

  - 资源利用率低
  - 可能发生饥饿

#### 7.4.3 无抢占

- 可采取如下协议:
  - 如果一个进程持有资源并申请另一个被占用的资源, 那么当前进程占有资源都可被抢占
  - 通常用于状态可以保存和恢复的资源, 如 CPU 寄存器和内存, 不适用于互斥锁和信号量

#### 7.4.4 循环等待

- 对所有资源类型进行完全排序, 并要求每个进程按照递增顺序来申请资源

### 7.5 死锁避免

- 进程事先声明可能需要的每种类型资源的最大数量, 鉴于这个先验信息可能构造一个算法来确保系统不会进入死锁状态
- 死锁避免算法动态检查资源分配状态, 来确保循环等待条件不能成立
- 资源分配状态包括可用资源、分配资源、进程最大需求

#### 7.5.1 安全状态

- **安全序列 (safe sequence)**: 系统按照该序列分配资源就能避免死锁, 那么系统处于**安全状态 (safe)**

  P_i 可申请到的资源 < 当前可用资源 + ∑进程 P_j 占有资源 (j<i)

#### 7.5.2 资源分配图算法

- **需求边 (claim edge)**: 表示在将来某个时刻 P 申请 R, 用虚线表示
- 假设 P 申请 Q, 只有在将申请边 P->Q 变为分配边 Q->P 并且不会导致资源分配出成环时, 才能通过申请, 采用环检测算法, O(n^2)

#### 7.5.3 银行家算法 (banker‘s algorithm)

- 可以处理多个资源实例的情况

- 进程进入前必须声明可能需要资源的最大数量

- 进程请求资源时可能等待

- 进程必须在有限时间内归还资源

- 定义数据结构有:

  - Available: 长度为 m 的向量, 表示每种资源的可用实例数量

  - Max: n*m 矩阵, 定义每个进程的最大需求

  - Allocation: n*m 矩阵, 定义每个进程已分配的资源数量

  - Need: n*m 矩阵, 定义每个进程仍需要的资源数量

    Need[i, j] = Max[i, j] - Allocation[i, j]

##### 7.5.3.1 安全算法

1. 令 Work 和 Finish 分别为长度 m, n 的向量, Work = Available, Finish = False

2. 查找 i 满足

   1. Finish[i] == false
   2. Need[i] <= Work

   若找不到, 则跳到 4

3. Work = Work + Allocation[i]

   Finish[i] = true

   回到 2

4. 若 Finish = true, 则系统处于安全状态

该算法 O(mn^2), 用于确定系统状态是否安全

##### 7.5.3.2 资源请求算法

令 Request[i] 为 P[i] 的请求向量, Request[i, j] = k 表示 P[i] 需要 k 个 R[j] 实例

1. 若 Request[i] <= Need[i], 转到 2. 否则生成出错条件.

2. 若 Request[i] <= Available, 转到 3. 否则等待

3. 修改状态

   Avaiable = Avaiable - Request[i]

   Allocation[i] = Allocation[i] + Request[i]

   Need[i] = Need[i] - Request[i]

   若新的分配状态时安全的, 那么交易完成, 否则进程 P[i] 应等待并恢复到原来的资源分配状态

### 7.6 死锁检测

- 若系统不预防死锁也不避免死锁, 可以提供:
  - 检查系统状态从而确定是否出现死锁的算法
  - 从死锁状态中恢复的算法

#### 7.6.1 每种资源类型只有单个实例

- **等待图 (wait-for graph)**: 将资源分配图中资源类型节点删去

  ![image-20230626000007854](/Users/qiu_nangong/Library/Application Support/typora-user-images/image-20230626000007854.png)

#### 7.6.2 每种资源类型可有多个实例

1. 设 Work 和 Finish 为长度 m, n 的向量, Work = Avaiable, Finish[i] = {Allocation[i] == 0}

2. 查找 i 满足

   1. Finish[i] = false
   2. Request[i] <= Work

   若找不到, 则跳到 4

3. Work = Work + Allocation[i]

   Finish[i] = true

   回到 2

4. 若存在 Finish[i] == false, 则系统死锁, 且 P[i] 死锁

算法 O(mn^2), 用于检测系统是否死锁

#### 7.6.3 应用检测算法

- 何时调用检测算法基于
  - 死锁发生频率
  - 死锁影响范围

### 7.7 死锁恢复

- 当确定有死锁是, 有以下方案:
  - 通知管理员人工处理死锁
  - 让系统从死锁状态中**自动恢复 (recover)**

#### 7.7.1 进程终止

- 通过终止进程来消除死锁
  - **终止所有死锁进程**
  - **一次终止一个进程, 直到消除死锁循环为止**
- 若采用部分终止, 应确定哪些进程应该终止, 类似于 CPU 调度, 影响因素包括:
  - 进程优先级
  - 进程运行时间, 剩余运行时间
  - 进程占有资源数, 资源是否可抢占
  - 进程还需多少资源
  - 需要终止进程数量
  - 进程是交互的还是批处理的

#### 7.7.2 资源抢占

- 通过抢占来处理死锁, 需要处理一下问题:
  - **选择牺牲进程**: 抢占哪些资源与哪些进程
  - **回滚**: 若抢占了一个资源, 对该进程回滚到一个安全状态, 以便其重启
  - **饥饿**: 如何保证不会发生饥饿, 即不会总是抢占某个进程资源

# Part.3 内存管理

## Chap.8 内存管理策略

### 8.1 背景

#### 8.1.1 基本硬件

- CPU 可直接访问的通用储存只有内存和处理器内置的寄存器

- **暂停 (stall)**: 访问内存需要多个 CPU 时钟周期, CPU 缺失数据完成任务

- **高速缓存 (cache)**: 解决暂停问题

- **基地址寄存器 (base register)**: 最小的合法的物理内存地址

  **界限地址寄存器 (limit register)**: 指定范围大小

- 硬件地址保护

  ![image-20230626004239951](/Users/qiu_nangong/Library/Application Support/typora-user-images/image-20230626004239951.png)

#### 8.1.2 地址绑定

- **输入队列 (input queue)**: 在磁盘上等待调到内存以便执行的进程
- **绑定 (bind)**: 将可重定位的地址绑定到绝对地址, 这样程序不必从 0000 开始执行
- 指令和数据绑定到储存器地址可在任何一步中进行:
  - **编译时 (compile time)**: 进程知晓内存中的驻留地址, 并生成**绝对代码 (absolute code)**
  - **加载时 (load time)**: 编译器生成**可重定位代码 (relocatable code)**, 绑定在加载时才进行
  - **执行时 (runtime time)**: 如果进程在执行时需要移动内存段, 绑定延迟到执行时才进行, 需要特定硬件支持, 为多数通用计算机操作系统采取的方法

#### 8.1.3 逻辑地址空间与物理地址空间

- **逻辑地址 (logical address)**: CPU 通常生成的地址

  **物理地址 (physical address) / 内存地址寄存器 (memory-address register)**: 内存单元所看到的地址

- 编译时和加载时的地址绑定方法生成相同的逻辑地址和物理地址, 而执行时的地址绑定方案生成不同的

  **虚拟地址 (virtual address)**: 执行时方法下的逻辑地址

- **逻辑地址空间 (logical address space)**: 逻辑地址的集合

  **物理地址空间 (physical address space)**: 逻辑地址对应的物理地址的集合

- **内存管理单元 (Memory_Management Unit, MMU)**: 虚拟地址到物理地址的运行时映射, 硬件设备

  **重定位寄存器 (relocation register)**: 基地址寄存器

#### 8.1.4 动态加载

- **动态加载 (dynamic loading)**: 仅在程序调用时加载, 未被调用时以可重定位加载格式存储在磁盘上, 减少了开销

#### 8.1.5 动态连接与共享库

- **动态连接库 (dynamically linked library)**: 可连接用户程序, 以便运行, 部分操作系统只支持**静态连接 (static linking)**
- **存根 (stub)**: 用来指出如何定位适当的内存驻留库程序, 或程序不在内存时如何加载库

### 8.2 交换

- 进程必须在内存中以便执行, 但可以暂时从内存**交换 (swap)** 到**备份存储 (backing store)**, 当再次执行时再调回内存

#### 8.2.1 标准交换

- 标准交换在内存和备份储存间移动进程, 备份存储通常是快速硬盘
- **就绪队列 (ready queue)**: 可运行的所有进程, 其映像在内存或备份存储中
- 重新换入的进程是否需要回到原物理地址取决于绑定方式
- 交换默认关闭, 仅在内存空间不足时开启, 问题解决后重新关闭
- 交换的时间开销非常大

#### 8.2.2 移动系统的交换

- 一般不支持交换
  - 移动系统通常使用闪存
    - 空间小
    - 写入次数限制
    - 吞吐量低
- iOS 要求应用自愿放弃内存. 只读数据从系统中删除, 需要时再重加载. 终止任何未能释放足够内存的应用
- Android 采用类似策略, 在终止进程之前, 将**应用程序状态 (application state)** 写到内存, 以便快速重启

### 8.3 连续内存分配

- 内存通常分为两个区域:

  - 驻留操作系统
  - 用户进程

  系统放在高内存还是低内存取决于中断向量的位置, 故一般放在低内存

- **连续内存分配 (contiguous memory allocation)**: 每个进程位于一个连续的内存区域, 与包含下一个进程的内存相连

#### 8.3.1 内存保护

#### 8.3.2 内存分配

- **多分区方法 (partition)**: 最简单的内存分配方法之一, 将内存分为多个固定大小的分区

- **可变分区 (variable-partition)**: 操作系统用一个表记录那些内存可用/已用

  - **孔 (hole)**: 一块连续可用内存

- 当进程进入系统时, 需要一个足够大的孔来存放, 分配方法通常有

  - **首次适应 (first-fit)**: 分配首个足够大的孔
  - **最优适应 (best-fit)**: 分配最小足够大的孔
  - **最差适应 (worst-fir)**: 分配最大的孔

  其中首次适应和最优适应较优, 且首次适应更快

#### 8.3.3 碎片

- **外部碎片 (external fragmentation)**: 总内存足够但其不连续
  - **50% 规则 (50-percent rule)**: 无论使用什么优化, N 个可分配块中总可能有 0.5N 个外部碎片, 即 1/3 的内存不能使用
- **内部碎片 (internal fragmentation)**: 进程分配的内存会比所需的要大, 其中多处部分无法利用
- **紧缩 (compaction)**: 解决外部碎片问题的方法, 通过移动内存内容, 将空闲空间合并, 仅在重定位是动态时才能进行.

### 8.4 分段

#### 8.4.1 基本方法

- 程序视作段的集合, 将内存视作不同长度的段
  - 代码
  - 全局变量
  - 堆
  - 每个线程使用的栈
  - 标准的 C 库
- 逻辑地址由有序对 <段号, 偏移> 组成

#### 8.4.2 分段硬件

- **段表 (segment table)**: 映射用户定义的二维地址到一维物理地址
  - **段基地址 (segment base)**
  - **段界限 (segment limit)**

### 8.5 分页

- **分页 (paging)** 可以避免外部碎片和紧缩, 也避免了不同大小内存块匹配到交换空间的问题

#### 8.5.1 基本方法

- **帧 (frame)**: 将物理内存分为固定大小的块

- **页 (page)**: 将逻辑内存分为同样大小的块

- **页码 (page number)**

  **页偏移 (page offset)**

  **页表 (page table)**

#### 8.5.2 硬件支持

- 简单方法: 将页表作为一组专用的寄存器来实现

- 页表较小时: 页表放在内存中, **页表基地址寄存器 (Page-Table Base Register, PTBR)** 指向页表

- **转换表缓冲区 (Translation Look-aside Buffer, TLB)**: 专用的、小的、查找快速的告诉硬件缓冲, 用来查找对应条目的页表

  - 若页码不在 TLB 中 (TLB miss), 则需要访问页表, 并将页码和帧码添加到 TLB 中

  - TLB 替换策略很多, 部分 CPU 允许操作系统参与

  - **命中率 (hit ratio)**

    **有效内存访问时间 (effective memory-access time, EAT)** = 命中率 * TLB 访问时间 + (1 - 命中率) * 通过页表访问时间

- 现代 CPU 可能提供多级 TLB

#### 8.5.3 保护

- 通过每个帧关联的保护位来实现, 保存在页表中
- **有效 - 无效位 (valid-invalid bit)**: 用来标识当前地址是否合法
- **页表长度寄存器 (Page-Table Length Register, PTLR)**: 表示页表的大小, 检测逻辑地址是否在有效范围之内

#### 8.5.4 共享页

- **可重入代码 (reentrant code) / 纯代码 (pure code)**: 可共享的代码, 不可自我修改, 在执行期间不会改变

### 8.6 页表结构

#### 8.6.1 分层分页

- **二级分页 / 向前映射页表 (forward-mapped page table)**: 将页表在分页, 并用外部页表映射到页表页

#### 8.6.2 哈希页表

- 采用虚拟页码作为哈希值

  ![image-20230626022347948](/Users/qiu_nangong/Library/Application Support/typora-user-images/image-20230626022347948.png)
  
- **聚簇页表 (clustered page table)**: 用于 64 位地址空间, 单个条目引用多个页, 在稀疏情况表现优异

#### 8.6.3 倒置页表 (inverted page table)

- 仅对帧才有条目, 保存在真正内存位置上的页的虚拟地址

  ![image-20230626022817885](/Users/qiu_nangong/Library/Application Support/typora-user-images/image-20230626022817885.png)

## Chap.9 虚拟内存管理

### 9.1 背景

- 许多情况下不需要将整个程序放于内存中:

  - 处理异常错误条件的代码, 极少使用
  - 数组、链表和表所分配的内存多于实际使用
  - 程序部分功能极少使用

- 即使需要整个程序, 也不一定同时需要:

  - 程序不再受物理内存可用量限制, 可以为巨大的虚拟空间编程
  - 每个用户程序占用较少的物理内存, 可以同时运行更多程序
  - 加载和交换到内存所需的 I/O 更少, 运行更快
  
- **虚拟内存 (virtual memory)**: 将用户逻辑内存和物理内存分开

  **虚拟地址空间 (virtual address space)**: 进程如何在内存中存放的逻辑
  
- 虚拟内存允许文件通过共享页来为多个进程共享:

  - 通过将共享对象映射到虚拟地址空间中, 系统库可以被多个进程共享
  - 允许进程共享内存
  - 通过 `fork()` 创建进程时, 可以共享页面, 加快进程创建

### 9.2 请求调页 (demand paging)

- 尽在需求时加载页面
- **惰性交换器 (lazy swapper)**: 除非需要某个页面, 否则不交换
- **调页程序 (pager)**: 使用 “交换器” 不准确, 交换器负责操纵整个进程, 而调页程序仅负责进程的页面

#### 9.2.1 基本概念

- 换入进程时调页程序会猜测在该进程被再次换出之前会用到哪些页, 仅将会被使用的页调入内存
  - 需要 MMU 支持请求调页
- **内存驻留 (memory resident)**
  - 所需页面已经在内存中, 那么和无请求调页情况相同
  - 所需页面不在内存中, 从存储中搜索页面并调入内存
    - 无需更改程序行为
    - 无需程序员更改代码
- **缺页错误 (page fault)**: 进程访问未被调入内存的页面, 处理缺页错误程序如下:
  - 检查进程的内部表 (通常与 PCB 一起保存), 确定引用的有效性
  - 如果引用无效, 那么终止进程. 如果引用有效, 那么将页面调入内存
  - 找到一个空闲帧
  - 调度一个磁盘操作, 将所需页面读到分配的帧
  - 当磁盘读物完成, 修改进程的内部表和页表, 指示该页现在处于内存当中
  - 重新启动被陷阱中断的指令, 该进程现在能访问所需的页面, 就好像其总是在内存中
- **纯请求调页 (pure demand paging)**: 执行没有内存页面的进程, 尽在需要时才将页面调入内存
  - **局部引用 (locality of reference)**: 防止每条指令引起多个缺页错误, 使得请求调页具有较为合理的性能

#### 9.2.2 请求调页的性能

- **有效访问时间 (effective access time, EAT)** = (1 - p) * 内存访问时间 (memory access time, MAT) + p * 缺页错误时间

  其中 p 为缺页错误的概率

- 缺页错误时间可有以下动作计算

  - 陷入操作系统
  - 保存用户寄存器和进程状态
  - 确定中断是否为缺页错误
  - 检查页面引用是否合法, 并确定页面的磁盘位置
  - 从磁盘读入页面到空闲帧
    - 在该磁盘队列中等待, 直到读请求被处理
    - 等待磁盘的寻道或延迟时间
    - 开始传输磁盘页面到空闲帧
  - 在等待时, 将 CPU 分配给其他用户 (可选)
  - 收到来自 I/O 子系统的中断 (I/O 完成)
  - 保存其他用户的寄存器和进程状态 (如果执行了 CPU 调度)
  - 确认中断是来自上述磁盘的
  - 修正页表和其他表, 以表示所需页面现在已在内存中
  - 等待 CPU 再次分配给本进程
  - 恢复用户寄存器、进程状态和新页表, 再重新执行中断的指令

  缺页错误的处理时间主要有三个主要组成部分:

  - 处理缺页错误中断
  - 读入页面
  - 重新启动进程

- 有效访问时间与**缺页错误率 (page-fault ratio)** 成正比

### 9.3 写时复制

- **写时复制 (copy-on-write)**: 允许父进程和子进程最初共享相同的页面来工作, 仅在写入共享页面时才创建副本
  - 仅在页面可修改时才需要标记为写时复制
- **页面池 (page pool)**: 存储空闲页面以供分配
  - **按需填零 (zero-fill-on-demand)**: 在需要分配前填零, 清除之前的内容

### 9.4 页面置换 (page replacement)

- **多道程度**: 由于不需要加载所有页面, 内存有更多帧页可供更多进程进入

- **过度分配 (over-allocating)**: 增加了多道程度后, 进程并发使用其所有页面, 导致内存无法分配
  - 当出现缺页错误时, 可能无空闲帧可供使用, 这是操作系统有多个选项:
    - 终止用户进程, 但该选项不是最佳的
    - 交换出一个进程, 释放其所有帧并降低多道程度
    - 常见解决方案是页面置换

#### 9.4.1 基本页面置换

- 若没有空闲帧, 查找一个当前不在使用的帧并释放

  - 找到所需页面的磁盘位置

  - 找到一个空闲帧:

    - 如果有空闲帧, 那么就使用它
    - 如果没有空闲帧, 那么就使用页面置换算法来选择一个**牺牲帧 (victim frame)**
    - 将牺牲帧的内容写到磁盘上, 修改对应的页表和帧表

  - 将所需页面读入空闲帧, 修改页表和帧表
  - 从发生缺页错误位置, 继续用户进程
  
- **修改位 (modify bit) / 脏位 (dirty bit)**: 减少页面置换开销, 当页面被修改过时设置修改位, 仅当修改位被设置时才将页面写入磁盘

- **帧分配算法 (frame-allocation algorithm)**

  - 每个进程分配多少帧
  - 选择牺牲帧

  **页面置换算法 (page-replacement algorithm)**

  - 追求最低缺页错误率
  - **引用串 (reference string)**: 针对特定内存引用串, 运行某个置换算法, 并计算缺页错误的数量
    - 跟踪一个给定系统并记录每个内存引用的地址, 只需考虑页码而非完整地址

#### 9.4.2 FIFO 页面置换

- **Belady 异常 (Belady's anomaly)**: 分配帧数量的增加, 缺页错误率可能会增加

#### 9.4.3 最优页面置换 (optimal page-replacement algorithm)

- 置换未来最长时间不会使用的页面
- 难以实现, 需要未知信息, 非在线做法

#### 9.4.4 LRU 页面置换

- **最近最少使用算法 (Least-Recent-Used algorithm, LRU algorithm)**: 置换过去最长时间没有使用的页
- LRU 置换算法有两种实现方法:
  - **计数器**: 为每个页表条目增加一个计数器, 记录最后引用的时间, 置换具有最小时间的页面
  - **堆栈**: 页面被引用是从堆栈中移除并放在顶部, 置换堆栈底部的页面
- LRU 置换没有 Belady 异常, 与最优置换统称为**堆栈算法  (stack algorithm)**

#### 9.4.5 近似 LRU 页面置换

- 极少有计算机系统提供足够硬件支持 LRU 页面置换算法, 但许多系统通过**引用位 (reference bit)** 形式提供一定支持
  - 最初, 所有引用位置 0, 当被引用时, 页面引用位置 1

##### 9.4.5.1 额外引用位算法

- 使用定时器周期将引用位设为移位寄存器高位, 并右移舍弃最低位, 具有最小移位寄存器值的页面被置换
- 移位寄存器极端情况下位数可为 0, 算法退化为**第二次机会页面置换算法 (second-chance page-replacement algorithm)**

##### 9.4.5.1 第二次机会算法

- 采用循环队列实现
  - 指针向前移动直到找到一个引用位为 0 的帧
  - 在移动过程中将引用位置 0

##### 9.4.5.3 增强型第二次机会算法

- 采用引用位和修改位作为有序对, (引用位, 修改位)

  显然最佳置换为 (0, 0)

#### 9.4.6 基于计数的页面置换

- **最不经常使用 (Least Frequently Used, LFU)**
- **最经常使用 (Most Frequently Used, MFU)**

#### 9.4.7 页面缓冲算法

#### 9.4.8 应用程序与页面置换

### 9.5 帧分配

#### 9.5.1 帧的最小数

#### 9.5.2 分配算法

- **平均分配 (equal allocation)**: 每个进程平均分配
- **比例分配 (proportional allocation)**: 根据进程大小分配

#### 9.5.3 全局分配与局部分配

- **全局置换 (global replacement)**: 在所有帧的集合选择一个, 不管是否已经分配给其他进程
- **局部置换 (local replacement)**: 在进程自己分配的帧中选择一个
- 全局置换系统吞吐量更好, 更为常用

#### 9.5.4 非均匀内存访问

- **非均匀内存访问 (Non-Uniform Memory Access, NUMA)**: 内存访问时间明显不同, 内存可能不位于同一主板

### 9.6 系统抖动

- **抖动 (thrashing)**: 若进程持续没有足够帧数运行, 则会反复产生缺页错误, 当调页时间多于执行时间, 那么进程就在抖动

#### 9.6.1 系统抖动的原因

- CPU 利用率低 -> 系统引入新的进程 -> 出现缺页错误 -> CPU 利用率进一步降低 -> 系统抖动
- 为了提高 CPU 利用率并停止抖动, 必须降低多道程度
- **局部置换算法 (local replacement algorithm) / 优先权置换算法 (priority replacement algorithm)** 可以限制系统抖动
  - 进程不能从别的进程取帧, 故不能导致别的进程抖动
  - 但调页设备平均等待时间更长了, 有效访问时间增加
- **局部性模型 (locality model)**: 随着进程执行, 从一个局部移向另一个局部, 局部可能重叠
  - 当局部的总面积 > 内存面积时, 抖动发生

#### 9.6.2 工作集模型

- **工作集模型 (working-set model)**: 基于局部性假设, 采用参数 Delta 定义**工作集窗口 (working-set window)**, 最近 Delta 个页面称为**工作集 (working-set)**
  - 设每个工作集的大小为 WSS[i], 易得到总需求量 D = ∑WSS[i]
  - 当 Delta 确定后, 工作集模型使用仅需保证: 为每个进程分配大于其工作集的帧数即可, 多余帧数可以分配给新进程
  - 工作集策略可以防止抖动, 并保持尽可能高的多道程度

#### 9.6.3 缺页错误频率 (Page-Fault Frequency, PFF)

- 通过控制缺页错误率的范围, 更为直接处理抖动问题

  ![image-20230626181015633](/Users/qiu_nangong/Library/Application Support/typora-user-images/image-20230626181015633.png)

### 9.7 内存映射文件

### 9.8 分配内核内存

### 9.9 其他注意事项

### 9.10 操作系统例子

# Part.4 存储管理

## Chap.10 文件系统

### 10.1 文件概念

- **文件 (file)**: 逻辑存储单位

#### 10.1.1 文件属性

- **名称**
- **标识符**
- **类型**
- **位置**
- **尺寸**
- **保护**
- **时间、日期和用户标识**
- **扩展文件属性**

#### 10.1.2 文件操作

- 基本文件操作:

  - **创建文件**

  - **写文件**

  - **读文件**

  - **重新定位文件**

  - **删除文件**

  - **截断文件**

- 打开文件的信息:
  - **文件指针**: 上次读写位置
  - **文件打开次数**
  - **文件的磁盘位置**
  - **访问权限**
- **文件锁**: 用于锁定打开的文件

#### 10.1.3 文件类型

#### 10.1.4 文件结构

#### 10.1.5 内部文件结构

### 10.2 访问方法

#### 10.2.1 顺序访问 (sequential access)

#### 10.2.2 直接访问 (direct access)

- 文件由固定长度的**逻辑记录 (logical records)** 组成, 允许程序按照任意顺序进行快速读取和写入记录

#### 10.2.3 其他访问方法

- **索引 (index)**

### 10.3 目录与磁盘的结构

- **分区 (partition)**
- **RAID 集**: 提供保护免受单个磁盘故障

#### 10.3.1 存储结构

#### 10.3.2 目录概述

- 目录执行操作:
  - **搜索文件**
  - **创建文件**
  - **删除文件**
  - **遍历目录**
  - **重命名文件**
  - **遍历文件系统**

#### 10.3.3 单级目录

#### 10.3.4 两级目录

#### 10.3.5 树形目录

#### 10.3.6 无环图目录

#### 10.3.7 通用图目录

### 10.4 文件系统安装

### 10.5 文件共享

#### 10.5.1 多用户



#### 10.5.2 远程文件系统

#### 10.5.3 一致性语义

### 10.6 保护

#### 10.6.1 访问类型

#### 10.6.2 访问控制

#### 10.6.3 其他保护方式

## Chap.11 文件系统实现

### 11.1 文件系统结构

- **块 (block)**: 内存和磁盘之间的 I/O 传输单位

- **文件系统 (file system)**: 提供高效和便捷的磁盘访问

  **I/O 控制 (I/O control)**: 包括设备驱动程序和中断处理程序, 以在主内存和磁盘系统之间传输信息

  **基本文件系统 (basic file system)**: 向适当设备驱动程序发送通用命令, 读取和写入磁盘的物理块

  **文件组织模块 (file-organization module)**: 知道文件及其逻辑块以及物理块

  **逻辑文件系统 (logical file system)**: 管理元数据信息, 包括文件系统的所有结构, 而不包括实际数据

  ![image-20230626194609918](/Users/qiu_nangong/Library/Application Support/typora-user-images/image-20230626194609918.png)

### 11.2 文件系统实现

#### 11.2.1 概述

- 文件系统包括如下信息:
  - 如何启动存储在那里的操作系统、总的块数、空闲块的位置和数量、目录结构以及各个具体文件
  - **引导控制块 (boot control block)**: 可以包含从该卷引导操作系统的所需信息
  - **卷控制块 (volume control block)**: 包括卷的详细信息, 如分区块的数量、块的大小、空闲块的数量和指针、空闲的 FCB 数量和指针等
  - 目录结构用于组织文件
  - 每个文件的 FCB 包括该文件的详细信息, 具有唯一标识号
- 内存中的信息用于管理文件系统, 在安装文件系统是被加载, 包括:
  - **安装表 (mount table)**: 包含每个安装卷的有关信息
  - 目录结构
  - **整个系统的打开文件表 (system-wide open-file table)**
  - **每个进程的打开文件表 (per-process open-file table)**
  - 对磁盘读出或写入时, 缓冲区保存文件系统的块

#### 11.2.2 分区与安装

#### 11.2.3 虚拟文件系统

- 文件系统的实现由三个主要层组成:

  - 文件系统接口

    - 基于 `open(), read(), write(), close()`

  - **虚拟文件系统 (Virtual File System, VFS)**

    - 通过定义一个清晰的 VFS 接口, 将文件系统的通用操作和实现分开
    - 提供一种机制, 以唯一标识网络上的文件
    - 区分本地文件和远程文件. 根据文件系统类型, 进一步区分本地文件

    Linux VFS 定义四种主要对象类型:

    - **索引节点对象 (inode object)**: 表示一个单独的文件
    - **文件对象 (file object)**: 表示一个已经打开的文件
    - **超级块对象 (superblock object)**: 表示整个文件系统
    - **目录条目对象 (dentry object)**: 表示单个目录条目

    VFS 并不知道或者不关心 inode 代表的是什么, 也不关心数据何时或如何被读取, 可以通过调用对象函数表内的适当函数进行操作,

### 11.3 目录实现

#### 11.3.1 线性列表

#### 11.3.2 哈希表

### 11.4 分配方法

#### 11.4.1 连续分配

- **连续分配 (contiguous allocation)**: 每个文件在磁盘上占有一组连续的块
  - 作业在访问磁盘时寻道时间最少
  - **动态存储分配 (dynamic storage-allocation)**: 寻找一个满足大小为 n 的空间
  - 有**外部碎片 (external fragmentation)** 的问题
  - 碎片整理

#### 11.4.2 链接分配 (linked allocation)

- 解决碎片的问题

- 只能用于顺序访问文件

- 指针空间占用

  - 将多个块组成**簇 (cluster)**

- 可靠性, 指针损坏或丢失可能导致故障

- **文件分配表** (File-Allocation Table, FAT)

  ![image-20230626201712035](/Users/qiu_nangong/Library/Application Support/typora-user-images/image-20230626201712035.png)

#### 11.4.3 索引分配 (indexed allocation)

- 通过将所有指针放在一块, 即**索引块 (index block)**

  ![image-20230626201956849](/Users/qiu_nangong/Library/Application Support/typora-user-images/image-20230626201956849.png)

- 索引块大小处理机制:

  - **连接方案**: 一个索引块为一个磁盘块
  - **多级索引**
  - **组合方案**: 部分指针指向**直接块 (direct block)**, 剩余三个指针指向:
    - **一级间接块 (single indirect block)**: 索引块, 包含块的地址
    - **二级间接块 (double indirect block)**: 包含了一个块的地址, 而这个块内的地址指向一些块, 这些块中又包含了真实数据块的指针
    - **三级间接块 (triple indirect block)**

#### 11.4.4 性能

### 11.5 空闲空间管理

#### 11.5.1 位向量

- **位图 (bit map) / 位向量 (bit vector)**

#### 11.5.2 链表

#### 11.5.3 组

#### 11.5.4 计数

#### 11.5.5 空间图

### 11.6 效率与性能

### 11.7 恢复

### 11.8 NFS

## Chap.12 大容量存储结构

### 12.1 大容量存储结构概述

### 12.2 磁盘结构

- **逻辑块 (logical block)**: 现代磁盘驱动器可以看做逻辑块的一位数组
  - **低级格式化 (low-level formatted)**: 选择不同逻辑块大小

### 12.3 磁盘链接

### 12.4 磁盘调度

- **寻道时间 (seek time)**: 磁臂移动磁头到包含目标扇区的柱面的时间
- **旋转延迟 (rotational latency)**: 磁盘旋转目标扇区到磁头下的额外时间
- **磁盘带宽 (disk bandwidth)**: 传输字节的总数除以从服务请求开始到最后传递结束时的总时间

#### 12.4.1 FCFS 调度

#### 12.4.2 SSTF 调度

- **最短寻道时间优先 (Shortest-Seek-Time-First, SSTF)**: 选择距离的当前磁头位置最近的请求, 可能导致饥饿

#### 12.4.3 SCAN 调度

- **扫描算法 (SCAN algorithm) / 电梯算法 (elevator algorithm)**: 从磁盘的一端开始, 到达另一端折返

#### 12.4.4 C-SCAN 调度

- **循环扫描 (Circular SCAN, C-SCAN)**: 从一段开始, 到达另一端返回起点

#### 12.4.5 LOOK 调度

- 从一段开始移动, 到达该方向的最远请求折返

#### 12.4.6 磁盘调度算法的选择

- SSTF 常见, 性能更好
- SCAN 和 C-SCAN 表现更好, 不太可能造成接问题
- SSTF 和 LOOK 是默认算法的合理选择



### 12.5 磁盘管理

### 12.6 交换空间管理

### 12.7 RAID 结构

- **磁盘冗余阵列 (Redundant Arrays of Independent Disk, RAID)**

#### 12.7.1 通过冗余提高可靠性

#### 12.7.2 通过并行处理提高性能

#### 12.7.3 RAID 级别

#### 12.7.4 RAID 级别的选择

#### 12.7.5 扩展

#### 12.7.6 RAID 的问题

### 12.8 稳定存储实现

## Chap.13 I/O 系统

### 13.1 概述

- **设备驱动程序 (device driver)**

### 13.2 I/O 硬件

- **总线 (bus)**: 一组线路和通过线路传输信息的严格定义的一个协议

  - **菊花链 (daisy chain)**

  